{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from jobspy import scrape_jobs\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs = scrape_jobs(\n",
    "#     site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\"],\n",
    "#     search_term=\"software engineer\",\n",
    "#     location=\"Dallas, TX\",\n",
    "#     results_wanted=20,\n",
    "#     hours_old=72, # (only Linkedin/Indeed is hour specific, others round up to days old)\n",
    "#     country_indeed='USA',  # only needed for indeed / glassdoor\n",
    "#     # linkedin_fetch_description=True # get full description and direct job url for linkedin (slower)\n",
    "# )\n",
    "# print(f\"Found {len(jobs)} jobs\")\n",
    "# print(jobs.head())\n",
    "# jobs.to_csv(\"jobs.csv\", quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False) # to_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_jobs = jobs.loc[:, (jobs.isna().sum() / jobs.shape[0]) < 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import numpy as np\n",
    "from psycopg2.extras import execute_values\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    if isinstance(text, str):  # Check if text is a string\n",
    "        response = openai.Embedding.create(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            input=text.replace(\"\\n\", \" \")\n",
    "        )\n",
    "        embedding = response['data'][0]['embedding']\n",
    "        return embedding\n",
    "    else:\n",
    "        return None  # Or an empty list or array, depending on your preference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Helper function: get embeddings for a text\n",
    "# def get_embeddings(text):\n",
    "#    response = openai.Embedding.create(\n",
    "#        model=\"text-embedding-ada-002\",\n",
    "#        input = text.replace(\"\\n\",\" \")\n",
    "#    )\n",
    "#    embedding = response['data'][0]['embedding']\n",
    "#    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl():\n",
    "    jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\"],\n",
    "    search_term=\"software engineer\",\n",
    "    location=\"San Francisco, CA\",\n",
    "    results_wanted=20,\n",
    "    hours_old=72, # (only Linkedin/Indeed is hour specific, others round up to days old)\n",
    "    country_indeed='USA',  # only needed for indeed / glassdoor\n",
    "    # linkedin_fetch_description=True # get full description and direct job url for linkedin (slower)\n",
    ")\n",
    "    logger.info(f\"{jobs.shape}\")\n",
    "    \n",
    "    # Transform\n",
    "    jobs['embeddings'] = jobs['description'].apply(lambda x: get_embeddings(x) if isinstance(x, str) else None)\n",
    "\n",
    "    # Load\n",
    "    connection = psycopg2.connect(\n",
    "        dbname=\"postgres\",\n",
    "        user=\"postgres\",\n",
    "        password=\"mypass\",\n",
    "        host=\"localhost\",  # or the database server IP address\n",
    "        port=\"5432\"        # default port for PostgreSQL\n",
    "    )\n",
    "    \n",
    "    cur = connection.cursor()\n",
    "    #install pgvector\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\");\n",
    "    connection.commit()\n",
    "    \n",
    "    \n",
    "    register_vector(connection)\n",
    "    \n",
    "    # Create table to store embeddings and metadata\n",
    "    table_create_command = \"\"\"\n",
    "    CREATE TABLE embeddings (\n",
    "                id bigserial primary key, \n",
    "                site text,\n",
    "                job_url text,\n",
    "                title text,\n",
    "                company text,\n",
    "                location text,\n",
    "                date_posted text,\n",
    "                interval text, \n",
    "                min_amount double precision,\n",
    "                max_amount double precision,\n",
    "                currency text,\n",
    "                is_remote text,\n",
    "                description text,\n",
    "                company_url text,\n",
    "                company_logo text,\n",
    "                embedding vector(1536)\n",
    "                );\n",
    "                \"\"\"\n",
    "    cur.execute(table_create_command)\n",
    "    cur.close()\n",
    "    connection.commit()\n",
    "    \n",
    "    #Batch insert embeddings and metadata from dataframe into PostgreSQL database\n",
    "    register_vector(connection)\n",
    "    cur = connection.cursor()\n",
    "    # Prepare the list of tuples to insert\n",
    "    data_list = [\n",
    "    (\n",
    "        row['site'],\n",
    "        row['job_url'],\n",
    "        row['title'],\n",
    "        row['company'],\n",
    "        row['location'],\n",
    "        row['date_posted'],\n",
    "        row['interval'],\n",
    "        row['min_amount'],\n",
    "        row['max_amount'],\n",
    "        row['currency'],\n",
    "        row['is_remote'],\n",
    "        row['description'],\n",
    "        row['company_url'],\n",
    "        row['company_logo'],\n",
    "        np.array(row['embeddings']).flatten()  # Flatten embeddings to ensure 1D\n",
    "    )\n",
    "    for index, row in jobs.iterrows()\n",
    "]\n",
    "\n",
    "    # Use execute_values to perform batch insertion\n",
    "    execute_values(\n",
    "        cur,\n",
    "        \"\"\"\n",
    "        INSERT INTO embeddings (site, job_url, title, company, location, date_posted, interval, min_amount, max_amount, currency, is_remote, description, company_url, company_logo, embedding)\n",
    "        VALUES %s\n",
    "        \"\"\",\n",
    "        data_list\n",
    "    )\n",
    "    \n",
    "    # commit after we insert all embeddings\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 16:39:50,728 - INFO - JobSpy:Indeed - search page: 1 / 1\n",
      "2024-11-11 16:39:50,729 - INFO - JobSpy:LinkedIn - search page: 1 / 2\n",
      "2024-11-11 16:40:56,405 - ERROR - JobSpy:LinkedIn - LinkedIn: HTTPSConnectionPool(host='www.linkedin.com', port=443): Max retries exceeded with url: /jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=software+engineer&location=San+Francisco%2C+CA&distance=50&pageNum=0&start=0&f_TPR=r259200 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='www.linkedin.com', port=443): Read timed out. (read timeout=10)\"))\n",
      "2024-11-11 16:40:56,406 - INFO - JobSpy:Linkedin - finished scraping\n"
     ]
    },
    {
     "ename": "TLSClientExeption",
     "evalue": "failed to do request: Get \"https://www.glassdoor.com//Job/computer-science-jobs.htm\": read tcp 10.8.16.39:52430->104.16.25.46:443: read: connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTLSClientExeption\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43metl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m, in \u001b[0;36metl\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21metl\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     jobs \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_jobs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msite_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindeed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinkedin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip_recruiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglassdoor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_term\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftware engineer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSan Francisco, CA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_wanted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhours_old\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m72\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# (only Linkedin/Indeed is hour specific, others round up to days old)\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcountry_indeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUSA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# only needed for indeed / glassdoor\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# linkedin_fetch_description=True # get full description and direct job url for linkedin (slower)\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjobs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Transform\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/site-packages/jobspy/__init__.py:125\u001b[0m, in \u001b[0;36mscrape_jobs\u001b[0;34m(site_name, search_term, google_search_term, location, distance, is_remote, job_type, easy_apply, results_wanted, country_indeed, hyperlinks, proxies, ca_cert, description_format, linkedin_fetch_description, linkedin_company_ids, offset, hours_old, enforce_annual_salary, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     future_to_site \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    121\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(worker, site): site \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m scraper_input\u001b[38;5;241m.\u001b[39msite_type\n\u001b[1;32m    122\u001b[0m     }\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(future_to_site):\n\u001b[0;32m--> 125\u001b[0m         site_value, scraped_data \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m         site_to_jobs_dict[site_value] \u001b[38;5;241m=\u001b[39m scraped_data\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_annual\u001b[39m(job_data: \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/site-packages/jobspy/__init__.py:116\u001b[0m, in \u001b[0;36mscrape_jobs.<locals>.worker\u001b[0;34m(site)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mworker\u001b[39m(site):\n\u001b[0;32m--> 116\u001b[0m     site_val, scraped_info \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_site\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m site_val, scraped_info\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/site-packages/jobspy/__init__.py:107\u001b[0m, in \u001b[0;36mscrape_jobs.<locals>.scrape_site\u001b[0;34m(site)\u001b[0m\n\u001b[1;32m    105\u001b[0m scraper_class \u001b[38;5;241m=\u001b[39m SCRAPER_MAPPING[site]\n\u001b[1;32m    106\u001b[0m scraper \u001b[38;5;241m=\u001b[39m scraper_class(proxies\u001b[38;5;241m=\u001b[39mproxies, ca_cert\u001b[38;5;241m=\u001b[39mca_cert)\n\u001b[0;32m--> 107\u001b[0m scraped_data: JobResponse \u001b[38;5;241m=\u001b[39m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscraper_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m cap_name \u001b[38;5;241m=\u001b[39m site\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mcapitalize()\n\u001b[1;32m    109\u001b[0m site_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZipRecruiter\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cap_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZip_recruiter\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cap_name\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/site-packages/jobspy/scrapers/glassdoor/__init__.py:69\u001b[0m, in \u001b[0;36mGlassdoorScraper.scrape\u001b[0;34m(self, scraper_input)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscraper_input\u001b[38;5;241m.\u001b[39mcountry\u001b[38;5;241m.\u001b[39mget_glassdoor_url()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m create_session(\n\u001b[1;32m     67\u001b[0m     proxies\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxies, ca_cert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert, is_tls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, has_retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 69\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_csrf_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgd-csrf-token\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;28;01melse\u001b[39;00m fallback_token\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mupdate(headers)\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/site-packages/jobspy/scrapers/glassdoor/__init__.py:157\u001b[0m, in \u001b[0;36mGlassdoorScraper._get_csrf_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_csrf_token\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Fetches csrf token needed for API by visiting a generic page\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Job/computer-science-jobs.htm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m([^\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]+)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    159\u001b[0m     matches \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(pattern, res\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/site-packages/tls_client/sessions.py:459\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    455\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m    458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request\"\"\"\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/site-packages/jobspy/scrapers/utils.py:98\u001b[0m, in \u001b[0;36mTLSRotating.execute_request\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxies \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 98\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mtls_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m response\u001b[38;5;241m.\u001b[39mok \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m400\u001b[39m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/reflex-job/lib/python3.12/site-packages/tls_client/sessions.py:442\u001b[0m, in \u001b[0;36mSession.execute_request\u001b[0;34m(self, method, url, params, data, headers, cookies, json, allow_redirects, insecure_skip_verify, timeout_seconds, proxy)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# --- Response -------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# Error handling\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TLSClientExeption(response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Set response cookies\u001b[39;00m\n\u001b[1;32m    444\u001b[0m response_cookie_jar \u001b[38;5;241m=\u001b[39m extract_cookies_to_jar(\n\u001b[1;32m    445\u001b[0m     request_url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    446\u001b[0m     request_headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    447\u001b[0m     cookie_jar\u001b[38;5;241m=\u001b[39mcookies,\n\u001b[1;32m    448\u001b[0m     response_headers\u001b[38;5;241m=\u001b[39mresponse_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    449\u001b[0m )\n",
      "\u001b[0;31mTLSClientExeption\u001b[0m: failed to do request: Get \"https://www.glassdoor.com//Job/computer-science-jobs.htm\": read tcp 10.8.16.39:52430->104.16.25.46:443: read: connection reset by peer"
     ]
    }
   ],
   "source": [
    "etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reflex-job",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
